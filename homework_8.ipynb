{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMJD78G0sWliFZsabwvJmr8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anananacr/ml-hw/blob/main/homework_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "fk9kfMY0OEyn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
        "#!unzip data.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "18iHaxue8bKw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_shape = (3, 200, 200)"
      ],
      "metadata": {
        "id": "b_oNfnv-OLhF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class HairClassifierMobileNet(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(HairClassifierMobileNet, self).__init__()\n",
        "\n",
        "        # Load pre-trained MobileNetV2\n",
        "        self.base_model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
        "\n",
        "        # Freeze base model parameters\n",
        "        for param in self.base_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Remove original classifier\n",
        "        self.base_model.classifier = nn.Identity()\n",
        "\n",
        "        # Add custom layers\n",
        "        self.conv2d = nn.Conv2d(out_channels = 32, kernel_size = (3,3), in_channels = 1280)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.reduce_map_size = nn.MaxPool2d(kernel_size = (2, 2))\n",
        "        self.linear_layer = nn.Linear(in_features=128, out_features=64)\n",
        "        self.output_layer = nn.Linear(in_features=64, out_features=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model.features(x)\n",
        "        x = self.conv2d(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.reduce_map_size(x)\n",
        "        x = torch.flatten(x,1)\n",
        "        x = self.linear_layer(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kZWwQlG7vaKv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def make_model(learning_rate=0.001):\n",
        "    model = HairClassifierMobileNet(\n",
        "        num_classes=1\n",
        "    )\n",
        "\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
        "    return model, optimizer"
      ],
      "metadata": {
        "id": "Zhi6AvU4zZZO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "model, optimizer = make_model()\n",
        "summary(model, input_size=(3, 200, 200))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "N2Ou6hZ019vV",
        "outputId": "e9b5f505-a5ca-4f42-b1e2-e167f4230f2d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 100, 100]             864\n",
            "       BatchNorm2d-2         [-1, 32, 100, 100]              64\n",
            "             ReLU6-3         [-1, 32, 100, 100]               0\n",
            "            Conv2d-4         [-1, 32, 100, 100]             288\n",
            "       BatchNorm2d-5         [-1, 32, 100, 100]              64\n",
            "             ReLU6-6         [-1, 32, 100, 100]               0\n",
            "            Conv2d-7         [-1, 16, 100, 100]             512\n",
            "       BatchNorm2d-8         [-1, 16, 100, 100]              32\n",
            "  InvertedResidual-9         [-1, 16, 100, 100]               0\n",
            "           Conv2d-10         [-1, 96, 100, 100]           1,536\n",
            "      BatchNorm2d-11         [-1, 96, 100, 100]             192\n",
            "            ReLU6-12         [-1, 96, 100, 100]               0\n",
            "           Conv2d-13           [-1, 96, 50, 50]             864\n",
            "      BatchNorm2d-14           [-1, 96, 50, 50]             192\n",
            "            ReLU6-15           [-1, 96, 50, 50]               0\n",
            "           Conv2d-16           [-1, 24, 50, 50]           2,304\n",
            "      BatchNorm2d-17           [-1, 24, 50, 50]              48\n",
            " InvertedResidual-18           [-1, 24, 50, 50]               0\n",
            "           Conv2d-19          [-1, 144, 50, 50]           3,456\n",
            "      BatchNorm2d-20          [-1, 144, 50, 50]             288\n",
            "            ReLU6-21          [-1, 144, 50, 50]               0\n",
            "           Conv2d-22          [-1, 144, 50, 50]           1,296\n",
            "      BatchNorm2d-23          [-1, 144, 50, 50]             288\n",
            "            ReLU6-24          [-1, 144, 50, 50]               0\n",
            "           Conv2d-25           [-1, 24, 50, 50]           3,456\n",
            "      BatchNorm2d-26           [-1, 24, 50, 50]              48\n",
            " InvertedResidual-27           [-1, 24, 50, 50]               0\n",
            "           Conv2d-28          [-1, 144, 50, 50]           3,456\n",
            "      BatchNorm2d-29          [-1, 144, 50, 50]             288\n",
            "            ReLU6-30          [-1, 144, 50, 50]               0\n",
            "           Conv2d-31          [-1, 144, 25, 25]           1,296\n",
            "      BatchNorm2d-32          [-1, 144, 25, 25]             288\n",
            "            ReLU6-33          [-1, 144, 25, 25]               0\n",
            "           Conv2d-34           [-1, 32, 25, 25]           4,608\n",
            "      BatchNorm2d-35           [-1, 32, 25, 25]              64\n",
            " InvertedResidual-36           [-1, 32, 25, 25]               0\n",
            "           Conv2d-37          [-1, 192, 25, 25]           6,144\n",
            "      BatchNorm2d-38          [-1, 192, 25, 25]             384\n",
            "            ReLU6-39          [-1, 192, 25, 25]               0\n",
            "           Conv2d-40          [-1, 192, 25, 25]           1,728\n",
            "      BatchNorm2d-41          [-1, 192, 25, 25]             384\n",
            "            ReLU6-42          [-1, 192, 25, 25]               0\n",
            "           Conv2d-43           [-1, 32, 25, 25]           6,144\n",
            "      BatchNorm2d-44           [-1, 32, 25, 25]              64\n",
            " InvertedResidual-45           [-1, 32, 25, 25]               0\n",
            "           Conv2d-46          [-1, 192, 25, 25]           6,144\n",
            "      BatchNorm2d-47          [-1, 192, 25, 25]             384\n",
            "            ReLU6-48          [-1, 192, 25, 25]               0\n",
            "           Conv2d-49          [-1, 192, 25, 25]           1,728\n",
            "      BatchNorm2d-50          [-1, 192, 25, 25]             384\n",
            "            ReLU6-51          [-1, 192, 25, 25]               0\n",
            "           Conv2d-52           [-1, 32, 25, 25]           6,144\n",
            "      BatchNorm2d-53           [-1, 32, 25, 25]              64\n",
            " InvertedResidual-54           [-1, 32, 25, 25]               0\n",
            "           Conv2d-55          [-1, 192, 25, 25]           6,144\n",
            "      BatchNorm2d-56          [-1, 192, 25, 25]             384\n",
            "            ReLU6-57          [-1, 192, 25, 25]               0\n",
            "           Conv2d-58          [-1, 192, 13, 13]           1,728\n",
            "      BatchNorm2d-59          [-1, 192, 13, 13]             384\n",
            "            ReLU6-60          [-1, 192, 13, 13]               0\n",
            "           Conv2d-61           [-1, 64, 13, 13]          12,288\n",
            "      BatchNorm2d-62           [-1, 64, 13, 13]             128\n",
            " InvertedResidual-63           [-1, 64, 13, 13]               0\n",
            "           Conv2d-64          [-1, 384, 13, 13]          24,576\n",
            "      BatchNorm2d-65          [-1, 384, 13, 13]             768\n",
            "            ReLU6-66          [-1, 384, 13, 13]               0\n",
            "           Conv2d-67          [-1, 384, 13, 13]           3,456\n",
            "      BatchNorm2d-68          [-1, 384, 13, 13]             768\n",
            "            ReLU6-69          [-1, 384, 13, 13]               0\n",
            "           Conv2d-70           [-1, 64, 13, 13]          24,576\n",
            "      BatchNorm2d-71           [-1, 64, 13, 13]             128\n",
            " InvertedResidual-72           [-1, 64, 13, 13]               0\n",
            "           Conv2d-73          [-1, 384, 13, 13]          24,576\n",
            "      BatchNorm2d-74          [-1, 384, 13, 13]             768\n",
            "            ReLU6-75          [-1, 384, 13, 13]               0\n",
            "           Conv2d-76          [-1, 384, 13, 13]           3,456\n",
            "      BatchNorm2d-77          [-1, 384, 13, 13]             768\n",
            "            ReLU6-78          [-1, 384, 13, 13]               0\n",
            "           Conv2d-79           [-1, 64, 13, 13]          24,576\n",
            "      BatchNorm2d-80           [-1, 64, 13, 13]             128\n",
            " InvertedResidual-81           [-1, 64, 13, 13]               0\n",
            "           Conv2d-82          [-1, 384, 13, 13]          24,576\n",
            "      BatchNorm2d-83          [-1, 384, 13, 13]             768\n",
            "            ReLU6-84          [-1, 384, 13, 13]               0\n",
            "           Conv2d-85          [-1, 384, 13, 13]           3,456\n",
            "      BatchNorm2d-86          [-1, 384, 13, 13]             768\n",
            "            ReLU6-87          [-1, 384, 13, 13]               0\n",
            "           Conv2d-88           [-1, 64, 13, 13]          24,576\n",
            "      BatchNorm2d-89           [-1, 64, 13, 13]             128\n",
            " InvertedResidual-90           [-1, 64, 13, 13]               0\n",
            "           Conv2d-91          [-1, 384, 13, 13]          24,576\n",
            "      BatchNorm2d-92          [-1, 384, 13, 13]             768\n",
            "            ReLU6-93          [-1, 384, 13, 13]               0\n",
            "           Conv2d-94          [-1, 384, 13, 13]           3,456\n",
            "      BatchNorm2d-95          [-1, 384, 13, 13]             768\n",
            "            ReLU6-96          [-1, 384, 13, 13]               0\n",
            "           Conv2d-97           [-1, 96, 13, 13]          36,864\n",
            "      BatchNorm2d-98           [-1, 96, 13, 13]             192\n",
            " InvertedResidual-99           [-1, 96, 13, 13]               0\n",
            "          Conv2d-100          [-1, 576, 13, 13]          55,296\n",
            "     BatchNorm2d-101          [-1, 576, 13, 13]           1,152\n",
            "           ReLU6-102          [-1, 576, 13, 13]               0\n",
            "          Conv2d-103          [-1, 576, 13, 13]           5,184\n",
            "     BatchNorm2d-104          [-1, 576, 13, 13]           1,152\n",
            "           ReLU6-105          [-1, 576, 13, 13]               0\n",
            "          Conv2d-106           [-1, 96, 13, 13]          55,296\n",
            "     BatchNorm2d-107           [-1, 96, 13, 13]             192\n",
            "InvertedResidual-108           [-1, 96, 13, 13]               0\n",
            "          Conv2d-109          [-1, 576, 13, 13]          55,296\n",
            "     BatchNorm2d-110          [-1, 576, 13, 13]           1,152\n",
            "           ReLU6-111          [-1, 576, 13, 13]               0\n",
            "          Conv2d-112          [-1, 576, 13, 13]           5,184\n",
            "     BatchNorm2d-113          [-1, 576, 13, 13]           1,152\n",
            "           ReLU6-114          [-1, 576, 13, 13]               0\n",
            "          Conv2d-115           [-1, 96, 13, 13]          55,296\n",
            "     BatchNorm2d-116           [-1, 96, 13, 13]             192\n",
            "InvertedResidual-117           [-1, 96, 13, 13]               0\n",
            "          Conv2d-118          [-1, 576, 13, 13]          55,296\n",
            "     BatchNorm2d-119          [-1, 576, 13, 13]           1,152\n",
            "           ReLU6-120          [-1, 576, 13, 13]               0\n",
            "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
            "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
            "           ReLU6-123            [-1, 576, 7, 7]               0\n",
            "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
            "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
            "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-129            [-1, 960, 7, 7]               0\n",
            "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-132            [-1, 960, 7, 7]               0\n",
            "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
            "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-138            [-1, 960, 7, 7]               0\n",
            "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-141            [-1, 960, 7, 7]               0\n",
            "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
            "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-147            [-1, 960, 7, 7]               0\n",
            "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-150            [-1, 960, 7, 7]               0\n",
            "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
            "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
            "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
            "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
            "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
            "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
            "          Conv2d-157             [-1, 32, 5, 5]         368,672\n",
            "            ReLU-158             [-1, 32, 5, 5]               0\n",
            "       MaxPool2d-159             [-1, 32, 2, 2]               0\n",
            "          Linear-160                   [-1, 64]           8,256\n",
            "            ReLU-161                   [-1, 64]               0\n",
            "          Linear-162                    [-1, 1]              65\n",
            "================================================================\n",
            "Total params: 2,600,865\n",
            "Trainable params: 376,993\n",
            "Non-trainable params: 2,223,872\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.46\n",
            "Forward/backward pass size (MB): 125.73\n",
            "Params size (MB): 9.92\n",
            "Estimated Total Size (MB): 136.11\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class HairDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.classes = sorted(os.listdir(data_dir))\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "\n",
        "        for label_name in self.classes:\n",
        "            label_dir = os.path.join(data_dir, label_name)\n",
        "            for img_name in os.listdir(label_dir):\n",
        "                self.image_paths.append(os.path.join(label_dir, img_name))\n",
        "                self.labels.append(self.class_to_idx[label_name])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "9mn-9UIJ8DAZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V7XrmzhZ8T4W"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    ) # ImageNet normalization\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    ) # ImageNet normalization\n",
        "])\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = HairDataset(\n",
        "    data_dir='./data/train',\n",
        "    transform=train_transforms\n",
        ")\n",
        "\n",
        "test_dataset = HairDataset(\n",
        "    data_dir='./data/test',\n",
        "    transform=test_transforms\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)"
      ],
      "metadata": {
        "id": "TIUivkPS2FHc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        # For binary classification with BCEWithLogitsLoss, apply sigmoid to outputs before thresholding for accuracy\n",
        "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_acc = correct_train / total_train\n",
        "    history['loss'].append(epoch_loss)\n",
        "    history['acc'].append(epoch_acc)\n",
        "\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            labels = labels.float().unsqueeze(1)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item() * images.size(0)\n",
        "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(test_dataset)\n",
        "    val_epoch_acc = correct_val / total_val\n",
        "    history['val_loss'].append(val_epoch_loss)\n",
        "    history['val_acc'].append(val_epoch_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
        "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWPgh4mg68e0",
        "outputId": "36f07ae3-48e4-456f-e186-fa3d1da2c3de"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.4655, Acc: 0.8215, Val Loss: 0.1594, Val Acc: 0.9801\n",
            "Epoch 2/10, Loss: 0.1145, Acc: 0.9663, Val Loss: 0.0966, Val Acc: 0.9701\n",
            "Epoch 3/10, Loss: 0.1037, Acc: 0.9588, Val Loss: 0.2091, Val Acc: 0.9154\n",
            "Epoch 4/10, Loss: 0.0804, Acc: 0.9738, Val Loss: 0.0423, Val Acc: 0.9851\n",
            "Epoch 5/10, Loss: 0.0533, Acc: 0.9863, Val Loss: 0.0410, Val Acc: 0.9851\n",
            "Epoch 6/10, Loss: 0.0339, Acc: 0.9913, Val Loss: 0.0527, Val Acc: 0.9801\n",
            "Epoch 7/10, Loss: 0.0369, Acc: 0.9813, Val Loss: 0.2058, Val Acc: 0.9055\n",
            "Epoch 8/10, Loss: 0.2106, Acc: 0.9451, Val Loss: 0.1255, Val Acc: 0.9453\n",
            "Epoch 9/10, Loss: 0.0730, Acc: 0.9800, Val Loss: 0.0747, Val Acc: 0.9701\n",
            "Epoch 10/10, Loss: 0.0445, Acc: 0.9888, Val Loss: 0.0660, Val Acc: 0.9751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.median(history['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auA4wkmh7L7X",
        "outputId": "3d33580c-0352-4d26-ee8a-9421b2ce0daf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.9769038701622972)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.std(history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEI1_qt0YFVv",
        "outputId": "ca3cfaf3-b2f4-4de8-980b-2bc868b95b00"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.12493360295541506)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225],\n",
        "    ), # ImageNet normalization\n",
        "    transforms.RandomRotation(50),\n",
        "    transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "])\n",
        "\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    ) # ImageNet normalization\n",
        "])\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = HairDataset(\n",
        "    data_dir='./data/train',\n",
        "    transform=train_transforms\n",
        ")\n",
        "\n",
        "test_dataset = HairDataset(\n",
        "    data_dir='./data/test',\n",
        "    transform=test_transforms\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)"
      ],
      "metadata": {
        "id": "c4p_OLshYcC2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        # For binary classification with BCEWithLogitsLoss, apply sigmoid to outputs before thresholding for accuracy\n",
        "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_acc = correct_train / total_train\n",
        "    history['loss'].append(epoch_loss)\n",
        "    history['acc'].append(epoch_acc)\n",
        "\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            labels = labels.float().unsqueeze(1)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item() * images.size(0)\n",
        "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(test_dataset)\n",
        "    val_epoch_acc = correct_val / total_val\n",
        "    history['val_loss'].append(val_epoch_loss)\n",
        "    history['val_acc'].append(val_epoch_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
        "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si-1cKj5YWS1",
        "outputId": "5033a217-d319-48ba-dcf1-62bb56bc2b3b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.1428, Acc: 0.9401, Val Loss: 0.0918, Val Acc: 0.9602\n",
            "Epoch 2/10, Loss: 0.0774, Acc: 0.9800, Val Loss: 0.0951, Val Acc: 0.9602\n",
            "Epoch 3/10, Loss: 0.0840, Acc: 0.9663, Val Loss: 0.0379, Val Acc: 0.9900\n",
            "Epoch 4/10, Loss: 0.0663, Acc: 0.9725, Val Loss: 0.1048, Val Acc: 0.9652\n",
            "Epoch 5/10, Loss: 0.0813, Acc: 0.9663, Val Loss: 0.0591, Val Acc: 0.9701\n",
            "Epoch 6/10, Loss: 0.1416, Acc: 0.9513, Val Loss: 0.0571, Val Acc: 0.9801\n",
            "Epoch 7/10, Loss: 0.0440, Acc: 0.9825, Val Loss: 0.0522, Val Acc: 0.9751\n",
            "Epoch 8/10, Loss: 0.0521, Acc: 0.9838, Val Loss: 0.0351, Val Acc: 0.9801\n",
            "Epoch 9/10, Loss: 0.0546, Acc: 0.9800, Val Loss: 0.0394, Val Acc: 0.9801\n",
            "Epoch 10/10, Loss: 0.0567, Acc: 0.9750, Val Loss: 0.0419, Val Acc: 0.9851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(history['val_loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpAOCe1fY-ic",
        "outputId": "722ceb43-5bed-44d3-fdc4-7aca7b52bcc1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.06144786900144959)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(history['val_acc'][5:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyWFQ8OiakW4",
        "outputId": "49f7f255-5998-4bcb-ac2b-a0c3687dddc8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.9800995024875622)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L-XIHqQBaz9B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}